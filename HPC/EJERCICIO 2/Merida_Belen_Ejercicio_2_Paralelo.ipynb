{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejercicio2-Paralelo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kG16snmtpSz"
      },
      "source": [
        "#**1 Introduccion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF3m0NalNeEn"
      },
      "source": [
        "En el siguiente cuaderno se realizara el producto entre dos matrices cuadradas, el resultado del producto es una nueva matriz. Es decir:\n",
        "\n",
        "<center>$\\ MR= A x B =A (a(11)...a(1n)) *B(b(11)...b(1n)) = (a(11)b(11)+ ... +a(1n)b(1n))$</center>\n",
        "\n",
        "Si bien el producto entre matrices tienen la propiedad de que el número de columnas de la matriz A tiene que ser igual al número de filas de la matriz B, en este ejercicio se opto por realizar el producto solo para matrices cuadradas.\n",
        "\n",
        "En cuanto a la descripcion de la paralelizacion:\n",
        "\n",
        "Como se ha definido cada bloque de forma bidimensional, se calculan índices de columnas y filas (después se convertirán a un índice lineal para hacer las operaciones).\n",
        "Se lanzan threads, que en cada uno de ellos se generará el cálculo de su correspondiente elemento en la matriz resultante. Para poder generar éste resultado, es necesario hacer un ciclo hasta \"n\" para hacer la sumatoria de las multiplicaciones necesarias. Para que la asignacion de la sumatoria en la matriz resultante sea correcta se sincronizan los hilos con __syncthreads() [1].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gA17EWGt7YT"
      },
      "source": [
        "#**2 Armando el ambiente**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ODYDyEMNTdx"
      },
      "source": [
        "Instala en el cuaderno el modulo de CUDA de python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtvPPSVKBG2c",
        "outputId": "8915c4ea-1e28-43ac-ec0a-ab37cb5e7ced"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 9.9MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=621008 sha256=45247d9ecb7bbebca337e28f14864f001ea485868fc7852040bddb1555d62b68\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=ca08b5a3829cbec5012ec4fb549207259ca18c0aa81249958353cda9373e65a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPLReEs4uH55"
      },
      "source": [
        "\n",
        "#**3 Desarrollo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVfLwJl7uLcM",
        "outputId": "3fbc1f68-8089-4c33-e58e-aa945d0335f8"
      },
      "source": [
        "# ------------------------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "f =   3#@param {type: \"number\"}\n",
        "c= 3#@param {type: \"number\"}\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from   pycuda.compiler import SourceModule\n",
        "\n",
        "import numpy\n",
        "import copy\n",
        "\n",
        "matriz_cpu = numpy.random.random((f,c)) *10\n",
        "matriz_cpu = matriz_cpu.astype(numpy.int32())\n",
        "\n",
        "matriz1 = numpy.random.random((f,c)) *10\n",
        "matriz1 = matriz1.astype(numpy.int32())\n",
        "\n",
        "matriz_r = numpy.random.random((f,c)) *10\n",
        "matriz_r = matriz_r.astype(numpy.int32())\n",
        " \n",
        "matriz_gpu = cuda.mem_alloc(matriz_cpu.nbytes)\n",
        "matriz1_gpu = cuda.mem_alloc(matriz1.nbytes)\n",
        "matrizr_gpu = cuda.mem_alloc(matriz_r.nbytes)\n",
        "\n",
        "cuda.memcpy_htod(matriz_gpu,matriz_cpu)\n",
        "cuda.memcpy_htod(matriz1_gpu,matriz1)\n",
        "cuda.memcpy_htod(matrizr_gpu,matriz_r)\n",
        "\n",
        "\n",
        "#CPU - Defino la funcion kernel que ejecutará en GPU\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void productoMatrices(int n, int *M1, int *M2, int *MR)\n",
        "{\n",
        "    int col = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "    int fila = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "    float suma=0;\n",
        "\n",
        "    if(col<n && fila<n)\n",
        "    {\n",
        "       for(int k=0; k<n;k++){\n",
        "         float a = M1[col*n+k];\n",
        "         float b = M2[k*n+fila];\n",
        "         suma+= a*b;\n",
        "       }\n",
        "       __syncthreads();\n",
        "       MR[col*n+fila] = suma;\n",
        "    }\n",
        "}\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "kernel = module.get_function(\"productoMatrices\")\n",
        "\n",
        "dim_hilo_x = 16\n",
        "dim_bloque_x = numpy.int( (f+dim_hilo_x-1) / dim_hilo_x )\n",
        "\n",
        "dim_hilo_y = 16\n",
        "dim_bloque_y = numpy.int( (c+dim_hilo_y-1) / dim_hilo_y )\n",
        "\n",
        "print( \"Thread x: \", dim_hilo_x, \", Bloque x:\", dim_bloque_x )\n",
        "print( \"Thread y: \", dim_hilo_y, \", Bloque y:\", dim_bloque_y )\n",
        "\n",
        "kernel( numpy.int32(f), matriz_gpu, matriz1_gpu, matrizr_gpu, block=( dim_hilo_x, dim_hilo_y, 1 ),grid=(dim_bloque_x, dim_bloque_y,1) )\n",
        "cuda.memcpy_dtoh(matriz_r,matrizr_gpu)\n",
        "\n",
        "print(\"Matriz 1: \")\n",
        "print(matriz_cpu)\n",
        "print(\"Matriz 2:\")\n",
        "print(matriz1)\n",
        "print(\"Resultado de la suma de matrices\")\n",
        "print(matriz_r)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread x:  16 , Bloque x: 1\n",
            "Thread y:  16 , Bloque y: 1\n",
            "Matriz 1: \n",
            "[[7 1 2]\n",
            " [0 8 3]\n",
            " [6 4 8]]\n",
            "Matriz 2:\n",
            "[[3 2 6]\n",
            " [3 6 9]\n",
            " [9 4 4]]\n",
            "Resultado de la suma de matrices\n",
            "[[ 42  28  59]\n",
            " [ 51  60  84]\n",
            " [102  68 104]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZmIaeOWuMe6"
      },
      "source": [
        "#**4 Tabla de pasos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIz9OJtNuWWl"
      },
      "source": [
        " Procesador | Funciòn | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tamaño de las matrices en Colab.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  numpy.random.randn( (n,n ) | Inicializa los Matrices.\n",
        "**GPU**  |  cuda.mem_alloc()      | Reserva la memoria en GPU.\n",
        "**GPU**  |  cuda.memcpy_htod()    | Copia las memorias desde el CPU al GPU.\n",
        "CPU      |  SourceModule()        | Define el código del kernel \n",
        "CPU      |  module.get_function() | Genera la función del kernel GPU\n",
        "CPU      |  dim_tx/dim_bx         | Calcula las dimensiones.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU\n",
        "CPU      |  cuda.memcpy_dtoh( )   | Copia el resultado desde GPU memoria matrizr_gpu a CPU memoria matriz_r.\n",
        "CPU      |  print()               | Informo los resultados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo5kasSpuYdf"
      },
      "source": [
        "#**5 Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzojGZyBv-pl"
      },
      "source": [
        "Se puede observar que en el producto de matrices en la GPU, debido a que un único thread se utiliza para calcular el valor de MR(i,j), la complejidad resultante[2] es O(N) que acomparacion del producto en el CPU [3] resulta ser mucho mas óptimo y por lo tanto mas rápido.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijf9m44xudLi"
      },
      "source": [
        "#**6 Bibliografia**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19Wiu4eS_0Ki"
      },
      "source": [
        "[1] Warps, Blocks, and Synchronization: [PDF](https://www.math.wsu.edu/math/kcooper/CUDA/13CUDAblock.pdf)\n",
        "\n",
        "[2] Complejidad Computacional:[PDF](https://www.frlp.utn.edu.ar/materias/algoritmos/GUIACOMPLEJIDADDEALGORITMOS.pdf)\n",
        "\n",
        "[3] Ejercicio Secuencial: [GITHUB](https://)"
      ]
    }
  ]
}